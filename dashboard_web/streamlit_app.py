# streamlit_app.py

import streamlit as st
import feedparser
import openai
import re
from datetime import datetime, date
from collections import Counter


# âœ… OpenAI ì„¤ì •
from openai import OpenAI
# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key = "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")

# âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_stock_news(query, max_results=10, only_today=False):
    rss_url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
    feed = feedparser.parse(rss_url)
    news_items = []

    for entry in feed.entries:
        summary_cleaned = re.sub('<[^<]+?>', '', entry.summary)

        try:
            published_dt = datetime(*entry.published_parsed[:6])
            published_str = published_dt.strftime("%Y-%m-%d %H:%M")
        except:
            published_dt = None
            published_str = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

        news_items.append({
            "title": entry.title,
            "link": entry.link,
            "summary": summary_cleaned,
            "published": published_str,
            "published_dt": published_dt
        })

    # âœ… ì˜¤ëŠ˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§
    if only_today:
        today = date.today()
        news_items = [item for item in news_items
                    if item["published_dt"] and item["published_dt"].date() == today]

    # âœ… ìµœì‹ ìˆœ ì •ë ¬
    news_items.sort(key=lambda x: x["published_dt"] or datetime.min, reverse=True)

    return news_items[:max_results]

# âœ… ê°ì„± ì¶”ì¶œ í•¨ìˆ˜
def extract_sentiment(text):
    match = re.search(r"\[ê°ì„±\]\s*(ê¸ì •|ë¶€ì •|ì¤‘ë¦½)", text)
    return match.group(1) if match else "ë¶„ë¥˜ ì‹¤íŒ¨"

# âœ… GPT ìš”ì•½ ë° ê°ì„± ë¶„ì„ í•¨ìˆ˜
def summarize_news_with_gpt(title, content):
    prompt = f"""
ë‹¤ìŒì€ ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤:

ì œëª©: {title}
ë‚´ìš©: {content}

1.ì´ ë‰´ìŠ¤ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
2.ë˜í•œ ì´ ë‰´ìŠ¤ê°€ íˆ¬ìì ì…ì¥ì—ì„œ ê¸ì •ì ì¸ì§€, ë¶€ì •ì ì¸ì§€, ì¤‘ë¦½ì ì¸ì§€ íŒë‹¨í•´ ì£¼ì„¸ìš”. (ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ)
3.ê·¸ë ‡ê²Œ íŒë‹¨í•œ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”:

[ìš”ì•½]
...

[ê°ì„±]
ê¸ì • / ë¶€ì • / ì¤‘ë¦½

[ì´ìœ ]
(ê°ì„± íŒë‹¨ ì´ìœ  ìš”ì•½)
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5
    )
    return response.choices[0].message.content

# âœ… íˆ¬ì ì˜ê²¬ ìš”ì•½ í•¨ìˆ˜
def generate_investment_opinion(news_summaries, stock_name):
    prompt = f"""
ë‹¹ì‹ ì€ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” '{stock_name}'ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤:

{news_summaries}

ì´ ì¢…ëª©ì˜ ìµœê·¼ì˜ ë‰´ìŠ¤ íë¦„ê³¼ ê°ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ íˆ¬ììì—ê²Œ ì¡°ì–¸ì„ í•´ ì£¼ì„¸ìš”.
'ë§¤ìˆ˜ ê³ ë ¤ / ê´€ë§ / ë¦¬ìŠ¤í¬ ì£¼ì˜' ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

[íˆ¬ì ì˜ê²¬]
ë§¤ìˆ˜ ê³ ë ¤ / ê´€ë§ / ë¦¬ìŠ¤í¬ ì£¼ì˜ ì¤‘ íƒ 1

[ì´ìœ ]
(ê°„ë‹¨í•œ ì„¤ëª…)
"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4
    )
    return response.choices[0].message.content

# âœ… Streamlit UI
st.title("ğŸ“ˆ ì¢…ëª© ë‰´ìŠ¤ ìš”ì•½ & ê°ì„± ë¶„ì„")
query = st.text_input("ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¼ì„±ì „ì)")
only_today = st.checkbox("ğŸ“… ì˜¤ëŠ˜ ë‰´ìŠ¤ë§Œ ë³´ê¸°")

if query:
    st.info(f'"{query}" ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...')
    news_list = get_stock_news(query, only_today=only_today)

    if not news_list:
        st.warning("ì˜¤ëŠ˜ ë‚ ì§œì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        sentiment_counter = Counter()
        summarized_texts = []
        results = []

        for i, news in enumerate(news_list):
            with st.spinner("ìš”ì•½ ë° ë¶„ì„ ì¤‘..."):
                result = summarize_news_with_gpt(news["title"], news["summary"])
            sentiment = extract_sentiment(result)
            sentiment_counter[sentiment] += 1
            summarized_texts.append(f"- {news['title']}: {result}")
            results.append((news, result))

        # âœ… ê°ì„± ìš”ì•½ í‘œì‹œ
        st.markdown("## ğŸ“Š ê°ì„± ë¶„ì„ ìš”ì•½")
        st.write(f"ğŸ‘ ê¸ì •: {sentiment_counter['ê¸ì •']}ê±´")
        st.write(f"ğŸ˜ ì¤‘ë¦½: {sentiment_counter['ì¤‘ë¦½']}ê±´")
        st.write(f"ğŸ‘ ë¶€ì •: {sentiment_counter['ë¶€ì •']}ê±´")
        st.markdown("---")

        # âœ… GPT íˆ¬ì ì˜ê²¬ í‘œì‹œ
        with st.spinner("GPTê°€ íˆ¬ì ì˜ê²¬ì„ ë¶„ì„ ì¤‘..."):
            opinion_result = generate_investment_opinion("\n".join(summarized_texts), query)

        st.markdown("## ğŸ§  GPT íˆ¬ì ì˜ê²¬")
        st.success(opinion_result)
        st.markdown("---")

        # âœ… ë‰´ìŠ¤ ì¶œë ¥
        for i, (news, result) in enumerate(results):
            st.subheader(f"ğŸ“° ë‰´ìŠ¤ {i+1}: {news['title']}")
            st.caption(f"ğŸ—“ ë‚ ì§œ: {news['published']}")
            st.write(f"[ì›ë¬¸ ë§í¬]({news['link']})")
            st.write(result)
